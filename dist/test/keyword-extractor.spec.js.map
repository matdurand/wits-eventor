{"version":3,"sources":["../../test/keyword-extractor.spec.js"],"names":["expect","require","describe","it","undefined","to","throw","Error","testFr","testEn","sentence","tokens","forEach","testCase","eql"],"mappings":";;AAAA;;AACA,IAAIA,SAASC,QAAQ,MAAR,EAAgBD,MAA7B;;AAEAE,SAAS,mBAAT,EAA8B,YAAM;;AAEhCC,OAAG,+CAAH,EAAoD,YAAM;AACtDH,eAAO;AAAA,mBAAM,wCAAiBI,SAAjB,EAA4B,EAA5B,CAAN;AAAA,SAAP,EAA8CC,EAA9C,CAAiDC,KAAjD,CAAuDC,KAAvD;AACH,KAFD;;AAIAJ,OAAG,+CAAH,EAAoD,YAAM;AACtDH,eAAO;AAAA,mBAAM,wCAAiB,IAAjB,EAAuBI,SAAvB,CAAN;AAAA,SAAP,EAAgDC,EAAhD,CAAmDC,KAAnD,CAAyDC,KAAzD;AACH,KAFD;;AAIAL,aAAS,QAAT,EAAmB,YAAY;AAC3B,YAAMM,SAAS,CACX,EADW,CAAf;AAIH,KALD;;AAOAN,aAAS,SAAT,EAAoB,YAAY;AAC5B,YAAMO,SAAS,CACX;AACIC,sBAAU,qDADd;AAEIC,oBAAQ,CAAC,UAAD,EAAa,UAAb,EAAyB,WAAzB,EAAsC,OAAtC,EAA+C,QAA/C;AAFZ,SADW,EAKX;AACID,sBAAU,kDADd;AAEIC,oBAAQ,CAAC,UAAD,EAAa,QAAb,EAAuB,WAAvB,EAAoC,YAApC;AAFZ,SALW,CAAf;;AAWAF,eAAOG,OAAP,CAAe,UAACC,QAAD,EAAc;AACzBV,eAAG,yCAAyCU,SAASH,QAAlD,GAA6D,GAAhE,EAAqE,YAAM;AACvE,oBAAMC,SAAS,wCAAiB,IAAjB,EAAuBE,SAASH,QAAhC,CAAf;AACAV,uBAAOW,MAAP,EAAeN,EAAf,CAAkBS,GAAlB,CAAsBD,SAASF,MAA/B;AACH,aAHD;AAIH,SALD;AAMH,KAlBD;;AAoBAT,aAAS,QAAT,EAAmB,YAAY;AAC3B,YAAMM,SAAS,CACX;AACIE,sBAAU,uEADd;AAEIC,oBAAQ,CAAC,UAAD,EAAa,QAAb,EAAuB,MAAvB,EAA+B,QAA/B;AAFZ,SADW,CAAf;;AAOAH,eAAOI,OAAP,CAAe,UAACC,QAAD,EAAc;AACzBV,eAAG,yCAAyCU,SAASH,QAAlD,GAA6D,GAAhE,EAAqE,YAAM;AACvE,oBAAMC,SAAS,wCAAiB,IAAjB,EAAuBE,SAASH,QAAhC,CAAf;AACAV,uBAAOW,MAAP,EAAeN,EAAf,CAAkBS,GAAlB,CAAsBD,SAASF,MAA/B;AACH,aAHD;AAIH,SALD;AAMH,KAdD;AAgBH,CArDD","file":"keyword-extractor.spec.js","sourcesContent":["import {generateKeywords} from \"../src/keyword-extractor\";\nvar expect = require('chai').expect;\n\ndescribe('keyword extractor', () => {\n\n    it('should throw an error with language undefined', () => {\n        expect(() => generateKeywords(undefined, '')).to.throw(Error);\n    });\n\n    it('should throw an error with sentence undefined', () => {\n        expect(() => generateKeywords('fr', undefined)).to.throw(Error);\n    });\n\n    describe('french', function () {\n        const testFr = [\n            \"\"\n        ];\n\n    });\n\n    describe('english', function () {\n        const testEn = [\n            {\n                sentence: \"tomorrow's practice cancelled, moved to next monday\",\n                tokens: [\"tomorrow\", \"practice\", \"cancelled\", \"moved\", \"monday\"]\n            },\n            {\n                sentence: \"a sentence ending with an ownership apostrophe's\",\n                tokens: [\"sentence\", \"ending\", \"ownership\", \"apostrophe\"]\n            }\n        ];\n\n        testEn.forEach((testCase) => {\n            it('should give the expected token for <' + testCase.sentence + '>', () => {\n                const tokens = generateKeywords('en', testCase.sentence);\n                expect(tokens).to.eql(testCase.tokens);\n            })\n        });\n    });\n\n    describe('french', function () {\n        const testFr = [\n            {\n                sentence: \"il y a une pratique demain à midi dans le deuxième champs de pratique\",\n                tokens: [\"pratique\", \"demain\", \"midi\", \"champs\"]\n            }\n        ];\n\n        testFr.forEach((testCase) => {\n            it('should give the expected token for <' + testCase.sentence + '>', () => {\n                const tokens = generateKeywords('fr', testCase.sentence);\n                expect(tokens).to.eql(testCase.tokens);\n            })\n        });\n    });\n\n});"]}